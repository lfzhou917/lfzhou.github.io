<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<style>
  .bottom-three {
     margin-bottom: 0.3mm;
  }
</style>
<title>Multi-Robot Coordination</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
<div class="menu-item"><a href="cool_robots.html">Cool Robots</a></div>
<!-- <div class="menu-item"><a href="pdfs/Lifeng_CV.pdf">CV</a></div> -->
<div class="menu-category">Contact</div>
<div class="menu-item"><a href="https://www.linkedin.com/in/lifeng-zhou-18135aa6/">Linkedin</a></div>
<div class="menu-item"><a href="https://twitter.com/Lifeng917">Twitter</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<!-- <h2>Research Statement</h2> -->
<p>
Today, robotics and autonomous systems have been increasingly used in various areas such as manufacturing, military, agriculture, medical sciences, and  environmental monitoring. However, most of these systems are fragile and vulnerable to adversarial attacks and uncertain environmental conditions. In most cases, even if a part of the system fails, the entire system performance can be significantly undermined. As robots start to coexist with humans, we need algorithms that can be trusted under real-world (not just ideal) conditions. To this end, my research focuses on enabling <b> security, trustworthiness, and long-term autonomy </b> in robotics and autonomous systems. I devise <i>efficient coordination algorithms with rigorous theoretical guarantees</i> to make robots resilient to attacks and aware of the loss from uncertainty. My long-term goal is to investigate <b>secure, reliable, and scalable multi-robot autonomy</b> when robots use data-driven machine learning techniques in the areas of <b> cyber-physical systems, the Internet of Things, precision agriculture, and smart cities.</b> 
</p>
<!-- My vision is to enable long-term deployments of robots performing tasks in real-world. Here, the robots have to deal with uncertain knowledge of the environment. The environment itself may be changing. Robots may fail or if they are operating in adversarial environments, they may get attacked. My goal is to devise algorithms to make the robots resilient to failure and be aware of the loss from uncertainty. To do that, the robots may have to communicate with each other to replan. I will specifically focus on strategies that are selective in who the robots communicate with and when to communicate.  -->
<a href="https://link.springer.com/article/10.1007/s43154-021-00046-5" target=&ldquo;blank&rdquo;>[Current Robotics Reports, 2021]</a>: Review on multi-robot coordination and planning in uncertain and adversarial environments.

<h2>Large-Scale, Decentralized Multi-Robot Coordination through Graph Neural Networks</h2>
<p><img src="photos/learning_framework.jpg" width="800"></img> <br>
For long-term operation in large-scale environments, we need scalable and decentralized algorithms. However, with local communications, these decentralized algorithms typically perform worse than their centralized counterparts. Recently, I have been exploring the use of <b>graph neural networks (GNNs)</b> as a tool for automatically synthesizing decentralized planning strategies which are trained to imitate centralized experts.
To this end, I developed a <b>GNN-based imitation learning framework</b> that learns <b>decentralized decision-making</b> for the robots from a <b>centralized expert</b> in <b>small-scale</b> scenarios and <b>generalizes well</b> the learned policies to <b>larger-scale</b> scenarios, e.g., larger environments and larger networks of robots. 
<p />
<a href="http://arxiv.org/abs/2105.08601" target=&ldquo;blank&rdquo;>[RA-L+IROS'22 submitted]</a>: Graph neural networks for decentralized multi-robot submodular action selection. 

<h2>Countering Attacks and Failures through Resilient Coordination</h2>
<!-- <img src="photos/uav_target.png" width="260", hspace="90"></img><img src="photos/tra_cover.png" width="280"></img> -->
<!-- <iframe width="410" height="200" src="https://www.youtube.com/embed/0pGrg514_eg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen> -->
</iframe> <iframe width="400" height="220" src="https://www.youtube.com/embed/T0Hb0UURCLM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <!-- 430*242 -->
</iframe> <iframe width="400" height="220" src="https://youtube.com/embed/hKOrFYUVjlo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 
<p>Most of the research on robot resiliency focuses on countering deceptive attacks that mislead the robot team. Instead, I have so far focused against <i>denial-of-service (DoS)</i> attacks and failures that can make robots fail or compromise their sensors. I aimed at guaranteeing team performance even if some robots in the team get DoS attacks. To this end, I formulated <b>game-theoretic problems</b> between the robots and the adversary, and designed <b>the first provably near-optimal approximation algorithms for robust combinatorial optimization</b> in various settings including centralized, decentralized communication and short-horizon, long-horizon planning. These algorithms enabled <b>DoS-resilient multi-robot planning</b> in data collection scenarios such as target tracking and environmental exploration. Apart from sensor attacks, the communications among robots can be easily jammed and disrupted by the adversary. Thus, I have recently investigated <b>near-optimal resilient algorithms</b> to protect the team performance from both <i>sensor and communication attacks/failures</i>.
</p>
<p>Besides the aforementioned resilient algorithms that can <b>withstand</b> attacks/failures, I am also interested in how robots should react to and recover from attacks/failures. To this end, we developed a resilient coordination framework that enables robots to <b>adapt and recover</b> by reconfiguring team resources to compensate for the performance loss induced by robot failures.
</p>
<a href="pdfs/RAL_target.pdf" target=&ldquo;blank&rdquo;>[RA-L+ICRA'19]</a>: Robust submodular maximization against robot/sensor attacks/failures;

<br><a href="https://ieeexplore.ieee.org/document/9197243" target=&ldquo;blank&rdquo;>[ICRA'20]</a>,<a href="https://arxiv.org/abs/1910.01208" target=&ldquo;blank&rdquo;> [T-RO accepted]</a>: Decentralized (clique-based) robust submodular maximization against robot/sensor attacks/failures (left video); 

<br> <a href="https://ieeexplore.ieee.org/abstract/document/9431677" target=&ldquo;blank&rdquo;>[RA-L'21]</a>: Distributed (consensus-based) robust submodular maximization against robot/sensor attacks/failures;

<br> <a href="https://roboticsconference.org/2020/program/papers/95.html" target=&ldquo;blank&rdquo;>[RSS'20]</a>, <a href="https://arxiv.org/abs/2003.13896" target=&ldquo;blank&rdquo;>[T-RO submitted]</a>: Robust team orienteering over a longer planning time against robot/sensor attacks/failures;

<br> <a href="https://arxiv.org/abs/2109.09838" target=&ldquo;blank&rdquo;>[ACC'22 invited paper, T-RO submitted]</a>: Robust monotone maximization against robot/sensor and communication attacks/failures;

<br> <a href="https://ieeexplore.ieee.org/document/9340871" target=&ldquo;blank&rdquo;>[IROS'20]</a>: Resilient coordination to adapt to and recover from robot/sensor failures (right video). 
<!-- </p>[<a href="https://youtu.be/xfMZloeKo6c" target=&ldquo;blank&rdquo;>Video</a>]</p> -->

<h2>Managing Risk through Stochastic Submodular Optimization</h2>

<img src="photos/simple_mod_exp.jpg" width="400" height="240"></img> 
<!-- <img src="photos/street_risk.png" width="220" hspace="40"></img> -->
</iframe> <iframe width="400" height="232" src="https://www.youtube.com/embed/atyBxxpqmCI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 

<p>In addition to failures caused by DoS attacks, robots can fail randomly, which adds <b>uncertainty</b> to their performance. More broadly, the uncertainty comes from noisy robot sensing, imperfect robot motion, and unknown environmental conditions. The uncertainty usually puts robots' performance at risk.</p>

<p> A standard strategy to deal with uncertainty is to optimize either the worst-case or the average of the stochastic performance. Both measures only consider a specific point of the distribution while not sufficiently utilizing the spread of the distribution. Instead, I utilized a risk measure, <b>Conditional-Value-at-Risk (CVaR)</b>, commonly used for risk management in stocks portfolio optimization. CVaR is calculated based on the distribution of performance outcomes. By optimizing CVaR, the robots can <i>manage the trustworthiness</i> of their decision-making by tuning a risk parameter. For example, with a high risk level, the robots make more <i>adventurous</i> decisions to gain more rewards (one average) but with higher uncertainty. Instead, if robots choose a low risk level, they are more <i>conservative</i> and achieve fewer rewards but with lower uncertainty. To this end, I proposed <b>the first polynomial-time algorithm that gives a bounded approximation for CVaR-based combinatorial optimization</b>. This trustworthy algorithm has been used for enabling <b>risk-aware multi-robot planning</b> in environmental monitoring and mobility-on-demand, stochastic traveling salesman problem, and for handling uncertainty extractions from <b>Bayesian  deep learning models</b>.</p>

<p> Along with optimizing CVaR for trustworthy decision-making, we designed a <b>Pareto optimization scheme</b> that adaptively balances maximizing team performance and minimizing risk of failures based on the abundance of <b>heterogeneous</b> team resources.</p>

<a href="https://link.springer.com/chapter/10.1007/978-3-030-44051-0_9" target=&ldquo;blank&rdquo;>[WAFR'18], <a href="https://arxiv.org/abs/2003.10492" target=&ldquo;blank&rdquo;>[T-RO accepted]</a>: Risk-aware submodular optimization to deal with uncertainties for multi-robot coordination (left figure). 

<br> <a href="https://arxiv.org/abs/2003.11675" target=&ldquo;blank&rdquo;>[IROS'20]</a>: Risk-aware planning and assignment for ground vehicles using uncertain perception from aerial vehicles; dealing with uncertain extractions from Bayesian deep learning. 

<br> <a href="https://arxiv.org/abs/2011.01095" target=&ldquo;blank&rdquo;>[IROS'21]</a>: Risk-aware submodular optimization for stochastic traveling salesperson problem. 

<br> <a href="https://arxiv.org/abs/2105.03813" target=&ldquo;blank&rdquo;>[RA-L+ICRA'22 accepted]</a>: Adaptive and risk-aware target tracking for robot teams with heterogeneous sensors (right video). 


<h2>Reducing Communication by Self-Triggered Control and Forming Subteams</h2>
<!-- <iframe width="410" height="200" src="https://www.youtube.com/embed/HO2dRSLk-Vc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
<iframe width="400" height="220" src="https://www.youtube.com/embed/UcsRCc9cfns" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="400" height="220" src="https://www.youtube.com/embed/YHz-NRubaAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Many challenges exist in the long-term autonomy of multi-robot systems, such as limited onboard battery capacity, heavy computation and communication load, and dangerous and uncertain outer environments. Among these challenges, my research focuses on <b>reducing communication costs</b> during coordination. Particularly, leveraging <b>self-triggered control</b>, I designed a <b>"when to communicate"</b> strategy that decides when a robot in the team should communicate to seek up-to-date information and when it is safe to operate with possibly outdated information. Even though the communication is restricted, this self-triggered strategy achieves similar performance to the all-time communication strategy, in theory, simulations, and a proof-of-concept experiment. To further reduce communication costs, I devised a <b>"who to communicate with"</b> strategy by forming robot subteams.  I proposed a <b>polynomial-time assignment algorithm</b> that provides a <b>provably near-optimal performance</b> even though the robots can only communicate within subteams.</p>

<a href="pdfs/ICRA_target.pdf" target=&ldquo;blank&rdquo;>[ICRA'17], <a href="pdfs/TASE_target.pdf" target=&ldquo;blank&rdquo;>[T-ASE'18]</a>: Active target tracking with self-triggered communications in multi-robot teams (left video). 

<br> <a href="pdfs/TRO_sensor.pdf" target=&ldquo;blank&rdquo;>[ICRA'20+T-RO'19]</a>: Sensor assignment algorithms to improve observability while tracking targets (right video). 

<!-- <h2>Reducing Communication by Forming Sensor Subsets</h2> -->
<!-- <iframe width="410" height="200" src="https://www.youtube.com/embed/Kt0yeYXyrKQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  -->
<!-- <br>
<p>We study two sensor assignment problems for multi-target tracking with the goal of improving the observability of the underlying estimator. We consider various measures of the observability matrix as the assignment value function. We first study the general version where the sensors must form teams to track individual targets. If the value function is monotonically increasing and submodular, then a greedy algorithm yields a 1/2–approximation. We then study a restricted version where exactly two sensors must be assigned to each target. We present a 1/3–approximation algorithm for this problem, which holds for arbitrary value functions (not necessarily submodular or monotone). In addition to approximation algorithms, we also present various properties of observability measures. We show that the inverse of the condition number of the observability matrix is neither monotone nor submodular, but present other measures that are. Specifically, we show that the trace and rank of the symmetric observability matrix are monotone and submodular and the log determinant of the symmetric observability matrix is monotone and submodular when the matrix is nonsingular. If the target’s motion model is not known, the inverse cannot be computed exactly. Instead, we present a lower bound for distance sensors. In addition to theoretical results, we evaluate our results empirically through simulations. -->


<h2>Saving Energy in Team Formation by Distributed Model Predictive Control</h2>
<img src="photos/flocking1.png" width="397"  hspace="5"></img>
<!-- <img src="photos/flocking2.png" width="360" hspace="10"></img> -->
<img src="photos/flocking3.png" width="397" ></img>
<p>We design a <b>distributed model predictive control (MPC)</b> strategy to achieve flocking of multi-agent systems. Based on the relative motion between each pair of neighboring agents, we introduce a <b>neighbor screening protocol</b>, by which each agent only focuses on its neighbors, which have the relative motion that violates the formation of flocks. Then, a truly distributed MPC flocking algorithm is designed with consideration of neighbor screening mechanism. Specifically, at each sampling instant, each agent monitors the information in the networked system, finds its neighbors to form its subsystem, determines the screened neighbor set, and optimizes its plan by collecting the position states within the screened subsystem. Geometric properties of the optimal path are used to guarantee the formation of the flock without inter-agent collision. Finally, the performance and advantage of the proposed distributed MPC flocking strategy are vividly verified by the simulation results.</p>

<a href="pdfs/IJRNC_flocking.pdf" target=&ldquo;blank&rdquo;>[IJRNC'17]</a>: Distributed model predictive control for multi-agent flocking via neighbor screening optimization (figures above). 

<br> <a href="pdfs/IET_consensus.pdf" target=&ldquo;blank&rdquo;>[IET'15]</a>: Distributed model predictive control for consensus of sampled-data multi-agent systems with double-integrator dynamics.

<br> <a href="pdfs/CCC_2015.pdf" target=&ldquo;blank&rdquo;>[CCC'15]</a>: Cooperative control of linear systems with coupled constraints via distributed model predictive control. 



<h2>Collaboration Work</h2>

<h3>Tree Search Application in Robot-Target Game</h3>
<img src="photos/tree_search.png" width="800">
<p>We introduce and study the problem of planning a trajectory for an agent to carry out a scouting mission while avoiding being detected by an adversarial guard. This introduces a multi-objective version of classical visibility-based target search and pursuit-evasion problem. In our formulation, the agent receives a positive reward for increasing its visibility (by exploring new regions) and a negative penalty every time it is detected by the guard. The objective is to find a finite-horizon path for the agent that balances the trade off between maximizing visibility and minimizing detectability.
<p/>
<p>
We model this problem as a <b>discrete, sequential, two-player, zero-sum game</b>. We use two types of game tree search algorithms to solve this problem: <b>minimax search tree and Monte-Carlo search tree</b>. Both search trees can yield the optimal policy but may require possibly exponential computational time and space. We propose several pruning techniques to reduce the computational cost while still preserving optimality guarantees. Simulation results show that the proposed strategy prunes approximately three orders of magnitude nodes as compared to the brute-force strategy. We also find that the Monte-Carlo search tree saves approximately one order of computational time as compared to the minimax search tree.
<p/>
<a href="pdfs/ICRA_tree.pdf" target=&ldquo;blank&rdquo;>[ICRA'19], <a href="https://link.springer.com/article/10.1007/s10514-020-09963-4" target=&ldquo;blank&rdquo;>[AURO'21]</a>: Game tree search for minimizing detectability and maximizing visibility.

<h3> Spoofing Strategy in Robot-Target Game</h3>
<img src="photos/spoof1.png" width="360" hspace="40">
</img><img src="photos/spoof2.png" width="360"></img>
<p>
We study the problem of <b>designing spoofing signals to corrupt and mislead the output of a Kalman filter</b>. Unlike existing works that focus on detection and filtering algorithms for the observer, we study the problem from the attacker’s point-of-view. In our model, the attacker can corrupt the measurements by adding spoofing signals. The attacker seeks to create a separation between the estimate of the Kalman filter with and without spoofing signals. We present a number of results on how to generate such spoofing signals, while minimizing the signal magnitude. The resulting algorithms are evaluated through simulations along with theoretical proofs.
</p>

<a href="pdfs/ACC_spoof.pdf" target=&ldquo;blank&rdquo;>[ACC'18], <a href="pdfs/TAC_spoof.pdf" target=&ldquo;blank&rdquo;>[TAC submitted]</a>: Strategies to inject spoofed measurement data to mislead Kalman filter. 

<div id="footer">
<div id="footer-text">
Page generated 2022-03-15, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
